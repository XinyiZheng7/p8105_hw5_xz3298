---
title: "p8105_hw5_xz3298"
author: "xinyi zheng"
date: "2023-11-08"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(readr)
library(forcats)
library(ggplot2)
```

# Problem 2
## List all the CSV files
```{r}

file_list <- list.files(path = "./data/", pattern = "\\.csv$", full.names = TRUE)

```

## Iterate over file names and read in data for each subject using purrr::map
```{r}
read_csv_and_add_ID <- function(x){
  out <- read.csv(x) |> 
    mutate("ID" = str_sub(x,8,13),"Arm" = str_sub(ID,1,3))
}

data0 <- map_vec(file_list, read_csv_and_add_ID)

view(data0)
```

## Manipulate and tidy the dataset
```{r}
data_long <- data0 |> 
  pivot_longer(
    cols = starts_with("week_"), 
    names_to = "week", 
    values_to = "value"
  ) 
```

## Create the spaghetti plot
```{r}
f1 <- ggplot(data_long, aes(week , value, group = ID, color = Arm)) + 
  geom_point() + 
  geom_line() + 
  ggtitle("Spaghetti Plot of Problem 2")
print(f1)

```
## Description of the plot

Starting Points: Both groups start at similar values close to zero in week 1, with the "/lex" group starting slightly lower than the "/co" group.
Variability: The "/lex" group exhibits a larger range of values over the eight weeks, indicating higher variability among its individuals compared to the "/co" group.
Trends: The "/lex" group shows a general upward trend, particularly noticeable from week 1 to week 4, and then continues to rise with some fluctuations. The "/co" group, after an initial drop, also trends upwards until week 5 but then shows a more marked decline.
Overlap and Crossings: There is considerable overlap between the groups, with multiple crossings of individual lines, suggesting that at various times across the weeks, individuals from one group may have higher or lower values than individuals from the other group.
Week-to-Week Changes: The week-to-week changes for individuals within the "/lex" group seem to be more pronounced compared to the "/co" group, which may indicate a higher within-group variance for the "/lex" group.


# Problem 3
## Set the hypothesis
```{r}
sim_mean_pvalue = function(n = 30, mu, sigma = 5, alpha = 0.05) {
  
  sim_data = tibble(
    x = rnorm(n, mean = mu, sd = sigma),
  )
  
  sim_data |> 
    summarize(
      mu_hat = mean(x),
      p_value = as.numeric(t.test(x) |> 
                             broom::tidy() |> 
                             select(p.value))
    )
}

ttest_simulation_function <- function(n_sim, mu) {
  output = vector("list", n_sim)
  for (i in 1:n_sim) {
    output[[i]] = sim_mean_pvalue(mu = mu)
  }
  sim_results = bind_rows(output) |> 
    mutate(mu = mu)
}

output = vector("list", 7)
for (i in 0:6) {
  output[[i + 1]] <- ttest_simulation_function(5000, mu = i)
}
sim_results_all = bind_rows(output)
```

## Plot 1
```{r}
p3_data1 <- sim_results_all |> 
  group_by(mu) |> 
  summarise(power = mean(p_value <= 0.05))

ggplot(data = p3_data1, aes(x = mu, y = power)) +
  geom_bar(stat = "identity", fill = "orange") +
  geom_text(aes(label = power), vjust = -0.3, size = 3.5) +
  theme_minimal() + 
  ggtitle("Barplot of power with respect to Mu")

```

## Description of plot 2



## Tidy and Combine the data
```{r}
p3_data2_part1 <- sim_results_all |> 
  group_by(mu) |> 
  summarise(mu_hat_mean = mean(mu_hat)) |> 
  mutate(flag = "All")

p3_data2_part2 <- sim_results_all |> 
  filter(p_value <= 0.05) |> 
  group_by(mu) |> 
  summarise(mu_hat_mean = mean(mu_hat)) |> 
  mutate(flag = "Subset which the null was rejected")

p3_data2 <- bind_rows(p3_data2_part1,p3_data2_part2)
```

## PLot 3
```{r}
ggplot(p3_data2, aes(x = mu, y = mu_hat_mean, group = flag)) +
  geom_line(aes(color = flag)) +
  geom_point(aes(color = flag)) + 
  ggtitle("mu_hat_mean with respect to mu")

```
## Description of plot 3
The red line is very close to the line y=x, which means when the number of simulations is very large, the average of mu_hat is very close to the true value.  

## Answer the questions:
The graph shows two lines: one representing the estimated mean (mu_hat_mean) for all tests, and the other for the subset of tests where the null hypothesis was rejected.
The line for "Subset which the null was rejected" (teal) shows higher values for mu_hat_mean compared to the line for "All" (red), especially as the true value of mu increases. This suggests that when the null hypothesis is rejected, the sample average of the estimated mean (mu_hat) tends to be higher than the true mean (mu). This could be due to the fact that when the null hypothesis is rejected, it’s often because the observed effect is large enough to be noticeable — which can result in an overestimate of the true effect, especially in the presence of random variation and sampling error.
Therefore, the sample average of mu_hat across tests for which the null is rejected is not approximately equal to the true value of mu. This overestimation is a result of the statistical phenomenon where larger observed effects are more likely to be statistically significant, and hence, more likely to lead to a rejection of the null hypothesis, even if those larger effects are partly due to chance. This is related to the concept of "regression to the mean", which can cause extreme values to arise naturally within a distribution of results, and selection bias, where only significant results are examined, ignoring those that do not reach the threshold of significance.

